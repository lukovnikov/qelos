{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import qelos as q\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "import numpy\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "\n",
    "from matplotlib import pyplot\n",
    "from matplotlib import gridspec\n",
    "%matplotlib inline\n",
    "import IPython\n",
    "from datetime import datetime as dt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Random Seed: ', 15042017)\n"
     ]
    }
   ],
   "source": [
    "opt_onesided = False     # use two-sided or one-sided constraint\n",
    "\n",
    "opt_penalty_weight = 10.0 # penalty weight term lambda\n",
    "\n",
    "opt_lip_mode = \"WGAN\"\n",
    "opt_dataset = 'swissroll' # 8gaussians | swissroll | 25gaussians\n",
    "opt_niter = 5000\n",
    "opt_batchSize=256\n",
    "opt_lrD = 0.00005 # learning rate for Critic, default=0.00005\n",
    "opt_lrG = 0.00005 # learning rate for Generator, default=0.00005\n",
    "opt_beta1=0.5 # beta1 for adam. default=0.5\n",
    "opt_cuda = torch.cuda.is_available\n",
    "opt_clamp_lower = -0.01 #default -0.01\n",
    "opt_clamp_upper =  0.01 #default  0.01\n",
    "opt_Diters = 10 # number of D iters per each G iter\n",
    "opt_adam = False  # Whether to use adam (default False is rmsprop)\n",
    "opt_prefix = None # whether to write images (=prefix of type string) or show in notebook (=None)\n",
    "\n",
    "opt_manualSeed = 15042017\n",
    "print(\"Random Seed: \", opt_manualSeed)\n",
    "random.seed(opt_manualSeed)\n",
    "numpy.random.seed(opt_manualSeed)\n",
    "torch.manual_seed(opt_manualSeed)\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dataset generator largely form Improved Training of Wasserstein GAN code (see link above)\n",
    "def inf_train_gen(DATASET='8gaussians', BATCH_SIZE=opt_batchSize):\n",
    "    numpy.random.seed(1234)\n",
    "    if DATASET == '25gaussians':\n",
    "        dataset = []\n",
    "        for i in range(100000//25):\n",
    "            for x in range(-2, 3):\n",
    "                for y in range(-2, 3):\n",
    "                    point = numpy.random.randn(2)*0.05\n",
    "                    point[0] += 2*x\n",
    "                    point[1] += 2*y\n",
    "                    dataset.append(point)\n",
    "        dataset = numpy.array(dataset, dtype='float32')\n",
    "        numpy.random.shuffle(dataset)\n",
    "        dataset /= 2.828 # stdev\n",
    "        while True:\n",
    "            for i in range(len(dataset)//BATCH_SIZE):\n",
    "                yield torch.from_numpy(dataset[i*BATCH_SIZE:(i+1)*BATCH_SIZE])\n",
    "\n",
    "    elif DATASET == 'swissroll':\n",
    "\n",
    "        while True:\n",
    "            data = sklearn.datasets.make_swiss_roll(\n",
    "                n_samples=BATCH_SIZE, \n",
    "                noise=0.25\n",
    "            )[0]\n",
    "            data = data.astype('float32')[:, [0, 2]]\n",
    "            data /= 7.5 # stdev plus a little\n",
    "            yield torch.from_numpy(data)\n",
    "\n",
    "    elif DATASET == '8gaussians':\n",
    "    \n",
    "        scale = 2.\n",
    "        centers = [\n",
    "            (1,0),\n",
    "            (-1,0),\n",
    "            (0,1),\n",
    "            (0,-1),\n",
    "            (1./numpy.sqrt(2), 1./numpy.sqrt(2)),\n",
    "            (1./numpy.sqrt(2), -1./numpy.sqrt(2)),\n",
    "            (-1./numpy.sqrt(2), 1./numpy.sqrt(2)),\n",
    "            (-1./numpy.sqrt(2), -1./numpy.sqrt(2))\n",
    "        ]\n",
    "        centers = [(scale*x,scale*y) for x,y in centers]\n",
    "        while True:\n",
    "            dataset = []\n",
    "            for i in range(BATCH_SIZE):\n",
    "                point = numpy.random.randn(2)*.02\n",
    "                center = random.choice(centers)\n",
    "                point[0] += center[0]\n",
    "                point[1] += center[1]\n",
    "                dataset.append(point)\n",
    "            dataset = numpy.array(dataset, dtype='float32')\n",
    "            dataset /= 1.414 # stdev\n",
    "            yield torch.from_numpy(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds1 = [next(inf_train_gen(\"swissroll\")) for i in range(100)]\n",
    "ds2 = [next(inf_train_gen(\"swissroll\")) for i in range(100)]\n",
    "for ds1e, ds2e in zip(ds1, ds2):\n",
    "    assert(numpy.allclose(ds1e.numpy(), ds2e.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generates and saves a plot of the true distribution, the generator, and the\n",
    "# critic.\n",
    "# largely form Improved Training of Wasserstein GAN code (see link above)\n",
    "class ImageGenerator:\n",
    "  def __init__(self, netG, netD, prefix='frame', noise_dim=2):\n",
    "    self.prefix = prefix\n",
    "    self.frame_index = 1\n",
    "    self.noise_dim = noise_dim\n",
    "    self.netG = netG\n",
    "    self.netD = netD\n",
    "    \n",
    "  def __call__(self, true_dist, perturbed, losses):\n",
    "    try:\n",
    "        N_POINTS = 128\n",
    "        RANGE = 2\n",
    "\n",
    "        points = numpy.zeros((N_POINTS, N_POINTS, 2), dtype='float32')\n",
    "        points[:,:,0] = numpy.linspace(-RANGE, RANGE, N_POINTS)[:,None]\n",
    "        points[:,:,1] = numpy.linspace(-RANGE, RANGE, N_POINTS)[None,:]\n",
    "        points = points.reshape((-1,2))\n",
    "        points = Variable(torch.from_numpy(points))\n",
    "        if true_dist.is_cuda:\n",
    "            points.cuda()\n",
    "\n",
    "        noise = torch.FloatTensor().resize_(opt_batchSize, 2)\n",
    "        noise.normal_(0, 1)\n",
    "        noise = Variable(noise)\n",
    "        if true_dist.is_cuda:\n",
    "            noise.cuda()\n",
    "\n",
    "        fake = self.netG(noise)\n",
    "        samples = fake.data.cpu().numpy()\n",
    "\n",
    "        disc_points = self.netD(points)\n",
    "\n",
    "        disc_map = disc_points.data.cpu().numpy()\n",
    "        disc_map = (disc_map - numpy.min(disc_map)) / numpy.max(disc_map) * 8\n",
    "        disc_map = numpy.log(disc_map + 0.25)\n",
    "\n",
    "        pyplot.figure(num=1, figsize=(10,15))\n",
    "        gs = gridspec.GridSpec(2, 1, height_ratios=[3, 1])\n",
    "\n",
    "        pyplot.clf()\n",
    "        if self.prefix is None:\n",
    "            #pyplot.suplots(nrows=1, ncols=2)\n",
    "            pyplot.subplot(gs[0])\n",
    "        x = y = numpy.linspace(-RANGE, RANGE, N_POINTS)\n",
    "        pyplot.contour(x,y,disc_map.reshape((len(x), len(y))).T)\n",
    "\n",
    "        true_dist = true_dist.cpu().numpy()\n",
    "        perturbed = perturbed.cpu().numpy()\n",
    "        pyplot.scatter(true_dist[:, 0], true_dist[:, 1], c='orange',marker='+')\n",
    "        pyplot.scatter(perturbed[:, 0], perturbed[:, 1], c='red', marker='+')\n",
    "        pyplot.scatter(samples[:, 0],   samples[:, 1],   c='green', marker='*')\n",
    "        if self.prefix is not None:\n",
    "          pyplot.savefig(self.prefix+'{:05d}'.format(self.frame_index)+'.jpg')\n",
    "        else:\n",
    "          pyplot.subplot(gs[1])\n",
    "          pyplot.plot(losses)\n",
    "          IPython.display.clear_output(wait=True)\n",
    "          IPython.display.display(pyplot.gcf())\n",
    "        self.frame_index += 1\n",
    "    except Exception:\n",
    "        print(\"some exception occurred while plotting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ToyGAN_G(nn.Module):\n",
    "    def __init__(self, dim_hidden=512, dim_out=2, noise_dim=2):\n",
    "        super(ToyGAN_G, self).__init__()\n",
    "        self.dim_hidden, self.dim_out, self.noise_dim = dim_hidden, dim_out, noise_dim\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(noise_dim, dim_hidden),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(dim_hidden, dim_hidden),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(dim_hidden, dim_hidden),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(dim_hidden, dim_out)\n",
    "            )\n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        return x\n",
    "\n",
    "class ToyGAN_D(nn.Module):\n",
    "    def __init__(self, dim_hidden=512, dim_gen_out=2):\n",
    "        super(ToyGAN_D, self).__init__()\n",
    "        self.dim_hidden, self.dim_gen_out = dim_hidden, dim_gen_out\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim_gen_out, dim_hidden),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(dim_hidden, dim_hidden),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(dim_hidden, dim_hidden),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(dim_hidden, 1)\n",
    "            )\n",
    "    def forward(self, x): #?\n",
    "        x = self.net(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AccLogger(object):\n",
    "    def __init__(self, follow=None):\n",
    "        self.follow = follow       \n",
    "        self.errD = []\n",
    "        self.errG = []\n",
    "        self.scoreD_real = []\n",
    "        self.scoreD_fake = []\n",
    "        self.lip_loss = []\n",
    "\n",
    "    def log(self, errD=None, errG=None, scoreD_real=None, scoreD_fake=None, lip_loss=None, **kw):\n",
    "        self.errD.append(errD)\n",
    "        self.errG.append(errG)\n",
    "        self.scoreD_real.append(scoreD_real)\n",
    "        self.scoreD_fake.append(scoreD_fake)\n",
    "        self.lip_loss.append(lip_loss)\n",
    "        if self.follow is not None:\n",
    "            self.follow.log(errD=errD, errG=errG, scoreD_real=scoreD_real, scoreD_fake=scoreD_fake, lip_loss=lip_loss, **kw)\n",
    "        \n",
    "    def get_acc(self):\n",
    "        return self.errD, self.errG, self.scoreD_real, self.scoreD_fake, self.lip_loss\n",
    "    \n",
    "    \n",
    "class ProgressLogger(object):\n",
    "    def __init__(self, imggen, follow=None, iterval=50):\n",
    "        self.follow = follow\n",
    "        self.imggen = imggen\n",
    "        self.iterval = 50\n",
    "        self.losses = []\n",
    "        \n",
    "    def log(self, _iter=None, niter=None, errD=None, errG=None, scoreD_real=None, scoreD_fake=None, lip_loss=None, \n",
    "            real=None, grad_points=None, **kw):\n",
    "        if (_iter+1) % self.iterval == 0:\n",
    "          self.losses.append(errD)\n",
    "          if grad_points is None:\n",
    "            grad_points = real\n",
    "          self.imggen(real, grad_points, losses)\n",
    "          print(\"Method: {} with penalty weight {}, {}-sided penalty\".format(name, penalty_weight, \"one\" if onesided else \"two\"))\n",
    "          print('[%d/%d] Loss_D: %f Loss_G: %f Loss_D_real: %f Loss_D_fake %f Loss_lip %f'\n",
    "            % (batches+1, niter,\n",
    "            errD.data[0], errG.data[0], scoreD_real.data[0], scoreD_fake.data[0], lip_loss.data[0]))\n",
    "        if self.follow is not None:\n",
    "            self.follow.log(_iter=_iter, niter=niter, errD=errD, errG=errG, scoreD_real=scoreD_real, scoreD_fake=scoreD_fake, lip_loss=lip_loss, grad_points=grad_points, real=real, **kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_experiment(lip_mode=opt_lip_mode,    # WGAN/DRAGAN/...\n",
    "                   onesided = opt_onesided,\n",
    "                   penalty_weight = opt_penalty_weight, \n",
    "                   perturb_both = False, \n",
    "                   perturb_symmetric = False,\n",
    "                   perturb_scale=1.,\n",
    "                   niter=opt_niter, \n",
    "                   data_pregenerate=False,\n",
    "                   modeD=\"critic\",\n",
    "                   dataset=\"swissroll\",\n",
    "                   cuda=opt_cuda,\n",
    "                   batsize=256):\n",
    "    \n",
    "    netG = ToyGAN_G()\n",
    "    netD = ToyGAN_D()\n",
    "    \n",
    "    if opt_adam:\n",
    "        optD = optim.Adam(netD.parameters(), lr=opt_lrD)\n",
    "        optG = optim.Adam(netG.parameters(), lr=opt_lrG)\n",
    "    else:\n",
    "        optD = optim.RMSprop(netD.parameters(), lr=opt_lrD)\n",
    "        optG = optim.RMSprop(netG.parameters(), lr=opt_lrG)\n",
    "    \n",
    "    plogger = ProgressLogger(ImageGenerator(netG, netD), iterval=2)\n",
    "    alogger = AccLogger(follow=plogger)\n",
    "    \n",
    "    gantrainer = q.GANTrainer(mode=lip_mode, modeD=modeD, one_sided=onesided, penalty_weight=penalty_weight, \n",
    "                              perturb_both=perturb_both, perturb_symmetric=perturb_symmetric, perturb_scale=perturb_scale, \n",
    "                              clamp_weights_rng=(opt_clamp_lower, opt_clamp_upper), optimizerD=optD, optimizerG=optG, \n",
    "                              logger=alogger)\n",
    "    \n",
    "    datagen = inf_train_gen(dataset, batsize)\n",
    "    \n",
    "    gantrainer.train(netD, netG, niter=niter, niterD=10, batsizeG=batsize, data_gen=datagen, cuda=cuda)\n",
    "    \n",
    "    return alogger.get_acc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_n_experiments(n=1, savedir=\"experiments/\", savename=None, save=True,\n",
    "                      lip_mode=opt_lip_mode,\n",
    "                      onesided=opt_onesided,\n",
    "                      penalty_weight=opt_penalty_weight,\n",
    "                      perturb_both=False,\n",
    "                      perturb_symmetric=False,\n",
    "                      niter=opt_niter,\n",
    "                      data_pregenerate=False, \n",
    "                      modeD=\"critic\", \n",
    "                      **kw):\n",
    "    names = \"WGAN WGAN-GP DRAGAN DRAGAN-G DRAGAN-LG\".split()\n",
    "    \n",
    "    mat = numpy.zeros((niter, n, 5))\n",
    "    cols = [\"errD\", \"errG\", \"scoreD_real\", \"scoreD_fake\", \"lip_loss\"]\n",
    "    for ni in range(n):\n",
    "        errD, errG, scoreD_real, scoreD_fake, lip_loss = run_experiment(lip_mode=lip_mode, \n",
    "                                                                        onesided=onesided, \n",
    "                                                                        penalty_weight=penalty_weight, \n",
    "                                                                        perturb_both=perturb_both,\n",
    "                                                                        perturb_symmetric=perturb_symmetric,\n",
    "                                                                        niter=niter,\n",
    "                                                                        data_pregenerate=data_pregenerate,\n",
    "                                                                        modeD=modeD,\n",
    "                                                                        **kw)\n",
    "        mat[:, ni, 0] = errD\n",
    "        mat[:, ni, 1] = errG\n",
    "        mat[:, ni, 2] = scoreD_real\n",
    "        mat[:, ni, 3] = scoreD_fake\n",
    "        mat[:, ni, 4] = lip_loss\n",
    "        \n",
    "    multiindex = [reduce(lambda x, y: x + y, [[i+1]*mat.shape[1] for i in range(mat.shape[0])], []),\n",
    "                  reduce(lambda x, y: x + y, [[j+1 for j in range(mat.shape[1])] for i in range(mat.shape[0])], [])]\n",
    "    \n",
    "    flatmat = mat.reshape((-1, mat.shape[-1]))\n",
    "    #flatmat = np.concatenate([np.asarray(multiindex).T, flatmat], axis=1)\n",
    "    mi = pd.MultiIndex.from_arrays(multiindex, names=\"iter run\".split())\n",
    "    df = pd.DataFrame(flatmat, index=mi, columns=cols)\n",
    "    \n",
    "    if savename is None:\n",
    "        extraoptstring = \"\"\n",
    "        if lip_mode in \"DRAGAN DRAGAN-G DRAGAN-LG\":\n",
    "            extraoptstring += \"_pboth={}\".format(int(perturb_both))\n",
    "        if lip_mode == \"DRAGAN\":\n",
    "            extraoptstring += \"_psym={}\".format(int(perturb_symmetric))\n",
    "        savename = \"{}_os={}_pw={}{}_niter={}_at_{}\".format(\n",
    "            lip_mode, int(onesided), penalty_weight, extraoptstring, niter,\n",
    "            str(dt.now()).replace(\" \", \"_\"))\n",
    "    savep = savedir + savename\n",
    "    if save:\n",
    "        df.to_csv(savep)\n",
    "        loadeddf = pd.read_csv(savep, index_col=[0, 1], skipinitialspace=True)\n",
    "        #return loadeddf\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_list_of_experiments(*specs):  # specs must be dictionaries (see example in next cell)\n",
    "    for spec in specs:\n",
    "        # rename long kw names\n",
    "        rename_dic = {\"lm\": \"lip_mode\", \n",
    "                      \"pw\": \"penalty_weight\", \n",
    "                      \"os\": \"onesided\", \n",
    "                      \"pboth\": \"perturb_both\", \n",
    "                      \"psym\": \"perturb_symmetric\", \n",
    "                      \"pscale\": \"perturb_scale\"}\n",
    "        for rde in rename_dic:\n",
    "            if rde in spec:\n",
    "                spec[rename_dic[rde]] = spec[rde]\n",
    "                del spec[rde]\n",
    "        run_n_experiments(**spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run_experiment(lip_mode=\"WGAN-GP\", cuda=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
